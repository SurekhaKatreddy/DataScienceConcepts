<img width="575" alt="image" src="https://user-images.githubusercontent.com/31846843/176092544-812f2c74-1331-4acf-83f5-ccce8912a165.png">

# NLP

# Remove punctuations
# Tokenize
# Rmove Stopwords

# Stemming : Store the root word. Helps identify the words with the same meaning thereby reducing the size of the corpus.
<img width="963" alt="image" src="https://user-images.githubusercontent.com/31846843/176087643-cb87a9ad-313d-44dc-89cd-1c2aefc2d7df.png">

<img width="911" alt="image" src="https://user-images.githubusercontent.com/31846843/176091636-52fae883-2e35-4a8f-9e51-7817b2dba081.png">

<img width="284" alt="image" src="https://user-images.githubusercontent.com/31846843/176091825-bbd8992a-7fec-42ed-8c4e-f0a725b3e8dd.png">

# Vectorizer : Edncode text as integers to create feature vectors
Types of vectorizations
 1. Count vectorization : results in a sparse matrix
 2. N-Grams
 3. TF-IDF : Term frequence Inverse document frequency.
<img width="692" alt="image" src="https://user-images.githubusercontent.com/31846843/176092292-6de08506-5596-4334-a5f6-f9ab0798c456.png">



